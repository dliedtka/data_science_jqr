# 3.6.3 Probability/Information Theory - Sampling Techniques

## a. Probability Sampling 
- Probability sampling is a method of selecting a sample from a population in which each member of the population has a known and non-zero chance of being selected. The purpose of probability sampling is to ensure that the sample accurately represents the population by reducing the potential for bias and increasing the precision of the sample statistics. This allows researchers to make inferences about the population based on the sample data, and to quantify the uncertainty associated with those inferences. Some common types of probability sampling include simple random sampling, stratified random sampling, and cluster sampling. The choice of probability sampling method depends on the goals of the study, the structure of the population, and the resources available.

## b. Monte Carlo Methods
- Monte Carlo methods are a class of computational algorithms that use random sampling to solve mathematical problems. The basic idea behind Monte Carlo methods is to use random samples to simulate a process and obtain statistical information about the output of the process. The purpose of Monte Carlo methods is to approximate solutions to complex mathematical problems for which analytical solutions are not available, and to estimate the uncertainties associated with these solutions.
- Monte Carlo methods are widely used in various fields, including finance, engineering, physics, and computer science. For example, in finance, Monte Carlo methods are used to model the price movements of financial assets, to estimate the value of financial derivatives, and to manage risk. In engineering, Monte Carlo methods are used to model complex systems, to optimize designs, and to estimate the reliability of systems. In physics, Monte Carlo methods are used to study the behavior of particles in a system, and to simulate the evolution of physical processes over time.
- The use of Monte Carlo methods requires large amounts of computation and random sampling, but they offer several advantages over other methods, such as the ability to handle complex and highly variable problems, and the ability to quantify the uncertainty associated with the results.

## c. Resampling 
- Resampling is a statistical method that involves repeatedly sampling from a dataset with replacement to generate new datasets. The purpose of resampling is to use the existing data to estimate the variability of a statistical estimate and to make inferences about a population from a sample. Resampling provides an alternative to traditional statistical methods, which typically rely on large sample size assumptions and assumptions about the distribution of the population.
- Resampling methods can be divided into two categories: bootstrapping and cross-validation. Bootstrapping is a method for estimating the variability of a statistic by generating multiple new datasets from the original sample and computing the statistic of interest for each new dataset. Cross-validation is a method for evaluating the performance of a statistical model by dividing the data into subsets, using some of the data to fit the model and the remainder of the data to evaluate the model's performance.
- Resampling is widely used in various fields, including finance, biology, and engineering. For example, in finance, resampling can be used to estimate the variability of portfolio returns and to evaluate the performance of financial models. In biology, resampling can be used to estimate the variability of genetic data and to test hypotheses about the evolution of species. In engineering, resampling can be used to evaluate the performance of machine learning algorithms and to optimize the design of experiments.
- Resampling provides several advantages over traditional methods, including the ability to make inferences about a population from a sample without relying on large sample size assumptions and the ability to quantify the uncertainty associated with the results.
