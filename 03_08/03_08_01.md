# 3.8.1 Supervised Learning

## a. Regression vs. Classification
- Regression and classification are both types of supervised learning methods, but they are used for different tasks.
- Regression is a supervised learning method that is used to predict a continuous target variable based on one or more input features. The goal of regression is to find a function that maps the input features to the target variable, such that the function can be used to make predictions on new data. Examples of regression problems include predicting the price of a house based on its square footage, predicting the risk of a credit default based on a borrower's financial history, or predicting the yield of a crop based on weather data.
- Classification, on the other hand, is a supervised learning method that is used to predict a categorical target variable based on one or more input features. The goal of classification is to find a function that can assign a class label to a new data point based on its features. Examples of classification problems include identifying spam emails, recognizing handwriting, or diagnosing a medical condition based on symptoms.
- In general, regression is used when the target variable is continuous, while classification is used when the target variable is categorical. The choice between regression and classification will depend on the specific problem you are trying to solve and the nature of the target variable.
- Additionally, it's worth noting that There are various algorithms that can be used to perform regression and classification, some examples are linear and logistic regression, decision trees, random forests, support vector machines, k-nearest neighbors, and neural networks. These algorithms have their own strengths and weaknesses and choosing the right algorithm depends on the characteristics of the dataset and the specific problem you are trying to solve.

## b. Linear/Logistic Regression
- Linear regression and logistic regression are both types of supervised learning methods, but they are used for different tasks.
- Linear regression is a supervised learning method that is used to predict a continuous target variable based on one or more input features. The goal of linear regression is to find the best-fitting straight line (or hyperplane in higher dimensions) through the data. The best-fitting line is determined by minimizing the sum of the squared differences between the predicted values and the actual values. Linear regression can be used to model a wide variety of continuous relationships, such as the relationship between a person's age and income, or the relationship between the number of hours studied and the score on an exam.
- Logistic regression, on the other hand, is a supervised learning method that is used to predict a categorical target variable based on one or more input features. The goal of logistic regression is to find a function that can assign a class label to a new data point based on its features. The function used in logistic regression is called the logistic function (or sigmoid function) which maps the input features to a probability between 0 and 1. The probability can then be used to assign a class label to the data point. Logistic regression is used in binary classification problems, where the target variable can take on one of two possible values, such as "spam" or "not spam" or "cancerous" or "non-cancerous".
- In summary, linear regression is used to model the relationship between a continuous target variable and one or more input features, while logistic regression is used to model the relationship between a categorical target variable and one or more input features. Both techniques are widely used and have their own strengths and weaknesses depending on the problem, the data and the assumptions that you make.
- ADDITIONAL NOTES:
    - linear regression is a regression method
        - in a single feature example, optimize m and b in y=mx+b
        - mean squared error function to minimize: $E = 1/n * \sum^n_{i=0} (y_i - (m x_i + b))^2$
        - $\partial E/\partial m = 1/n \sum^n_{i=0} (2 * (y_i - (m x_i + b)) * (-x_i)) = -2/n \sum^n_{i=0} x_i (y_i - (m x_i + b))$ 
        - $\partial E/\partial b = 1/n \sum^n_{i=0} (2 * (y_i - (m x_i + b)) * (-1)) = -2/n \sum^n_{i=0} (y_i - (m x_i + b))$
        - update function: $m = m - \alpha * \partial E/ \partial m$, $b = b - \alpha * \partial E/ \partial b$
    - logistic regression is a classification method (not regression) 
        - $W$ is a 1-D vector, length is the number of features (n x 1)
        - $b$ is a constant
        - $X$ is (n x m), $Y$ is (1 x m)
        - sigmoid function: $\sigma = 1 / (1 + e^{-x})$
        - predictions (1 x m): $A = \sigma (W^T X + b)$
        - cost function: $c = - 1/m \sum^m_{i=1} [ y_i * \log(a_i) + (1 - y_i) * \log(1 - a_i) ]$
        - gradient descent: 
            - $dW = \partial c/\partial W = (A - Y) * X^T$ (1 x n)
            - $db = \partial c/\partial b = (A - Y)$
            - $W = W - \alpha dW^T$
            - $b = b - \alpha db$

## c. Nearest neighbors learning
- K-nearest neighbors (KNN) is a type of supervised learning method that is based on the idea of using the "similarity" of the data points to make predictions. The basic idea behind KNN is that a data point is assigned the same class label as the majority of its "k" closest neighbors.
- The purpose of KNN algorithm is to classify new data points based on their similarity to the data points in the training set. The algorithm doesn't make any assumptions about the functional form of the relationship between the features and the target variable and it is considered as a non-parametric method. It can be used for both classification and regression problems.
- The use of KNN algorithm is relatively simple, the training phase of the algorithm is just to memorize the training set, and the prediction is made at run-time. To classify a new data point, the algorithm finds the "k" closest data points in the training set and assigns the class label of the majority of these data points to the new data point. The value of "k" is a user-specified parameter that controls the smoothness of the decision boundary. A small "k" value will result in a more complex decision boundary and a large "k" value will result in a simpler decision boundary.
- KNN is considered as a simple and powerful algorithm, it can be used for a wide range of problems, such as image recognition, text classification, and anomaly detection. However, it has some disadvantages as well, such as high computational cost, large memory requirements, and sensitivity to irrelevant features and the scale of the data. Additionally, it's sensitive to the choice of distance metric used to compute similarity between the data points.

## d. Decision trees
- Decision trees are a type of supervised learning method that is used for both classification and regression problems. The goal of decision tree learning is to construct a decision tree model, which can be used to make predictions about the target variable based on the input features.
- A decision tree is a tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. Each internal node of the tree represents a test on an input feature, each branch represents the outcome of the test, and each leaf node represents a prediction or a class label.
- The purpose of decision trees is to learn a model that can be used to make predictions about the target variable based on the input features. The decision tree algorithm is designed to recursively split the data into subsets based on the values of the input features. The splits are chosen in a way that maximizes the separation of the classes for classification problems, or minimizes the variance for regression problems. The final result is a tree that can be used to make predictions about the target variable for new data points.
- Decision trees are easy to understand and interpret, making them a popular choice for both classification and regression problems, especially in the case of large datasets with many input features. They can also be easily visualized, which makes it easy to understand the relationships between the input features and the target variable. Decision trees are also relatively robust to outliers and can handle categorical and numerical input features. However, they can be easily prone to overfitting, especially when the tree is grown too deep. To solve this problem, it's common to use techniques such as pruning, or use random forest or gradient boosting decision tree algorithms.

## e. Support vector machines 
- Support Vector Machines (SVMs) are a type of supervised learning method that is used for classification and regression problems. The goal of SVM is to find a decision boundary that maximally separates the different classes in the data.
- In the case of classification problems, an SVM is a model that represents the data as points in a high-dimensional space, and finds a linear boundary that separates the different classes. The boundary is chosen in a way that maximizes the margin, which is the distance between the boundary and the closest data points from each class, known as the support vectors.
- SVMs can also be used for regression problems, in this case, the goal is to find a function that can predict a continuous target variable based on one or more input features. The function used in SVM is called the support vector regression function and it finds a linear boundary in the high-dimensional space that best separates the data points.
- The purpose of SVMs is to find a decision boundary that maximally separates the different classes in the data. The decision boundary found by an SVM is a linear boundary that maximizes the margin between the classes, which means that it is as far away as possible from the closest data points of each class. SVMs are particularly useful when the data is not linearly separable, in this case, they can be used with a technique called the kernel trick which maps the input data into a higher-dimensional space where a linear boundary can be found.
- SVMs are considered as powerful and versatile algorithm, they are particularly useful when the data is not linearly separable, and have been successfully used in a wide range of applications such as image recognition, text classification, and bioinformatics. However, they are sensitive to the choice of kernel function, and the parameters of the model, and can be sensitive to the scaling of the input features.

## f. Neural networks 
- Neural networks (NNs) are a type of supervised learning method that are inspired by the structure and function of the human brain. They are composed of interconnected nodes, called artificial neurons, that are organized into layers. The purpose of NNs is to learn a non-linear function that maps the input features to the target variable.
- NNs can be used for a wide range of tasks such as image recognition, natural language processing, and time series prediction. The type of NN architecture and the number of layers used in the model will depend on the specific problem you are trying to solve.
- One of the most popular types of neural network is the feedforward neural network, also known as multi-layer perceptron (MLP). This type of network is composed of an input layer, one or more hidden layers, and an output layer. The input layer receives the input features, and each hidden layer applies a non-linear transformation to the data, and the output layer produces the predictions. The goal of training a feedforward neural network is to find the weights of the connections between the layers that minimize the difference between the predicted and actual target values.
- Another popular type of neural network is the convolutional neural network (CNN) which is mainly used for image recognition and computer vision tasks. CNNs are designed to automatically and adaptively learn spatial hierarchies of features from input images. They are composed of multiple layers of convolutional and pooling layers, followed by one or more fully connected layers.
- Recurrent neural networks (RNN) are a type of neural network that are designed to process sequential data such as time series or natural language. RNNs are composed of recurrent connections that allow information to flow through the network even when the input data is changing. This allows the network to maintain a hidden state that can be used to make predictions based on the past observations.
- In summary, NNs are a powerful and versatile type of supervised learning method that can be used for a wide range of tasks such as image recognition, natural language processing, and time series prediction. They are able to learn non-linear relationships between the input features and the target variable and can be used to model a wide range of problems. However, they can be computationally intensive to train and can require a large amount of data to achieve good performance. Additionally, it can be difficult to interpret the decisions made by a neural network and it can be hard to diagnose and correct errors in the model.

## g. Naive Bayes
- Naive Bayes is a type of supervised learning method that is based on Bayes' theorem and is particularly useful for classification problems. The goal of Naive Bayes is to predict the class label of a new data point based on the probability of the data point belonging to each class, given the values of the input features.
- The "naive" part of the name comes from the assumption that the input features are independent of one another, given the class label. This assumption is not always true in real-world problems, but it allows the algorithm to make predictions based on the individual feature probabilities.
- There are several variants of Naive Bayes, including Gaussian Naive Bayes, Multinomial Naive Bayes, and Bernoulli Naive Bayes, each of them is used for different types of data.
- Gaussian Naive Bayes is used when the input features are continuous and are assumed to have a Gaussian distribution. It's commonly used in problems such as text classification and sentiment analysis.
- Multinomial Naive Bayes is used when the input features are count-based, such as word frequencies in text classification problems.
- Bernoulli Naive Bayes is used when the input features are binary, such as in text classification problems where a word is either present or absent.
- The purpose of Naive Bayes is to predict the class label of a new data point based on the probability of the data point belonging to each class, given the values of the input features. It's considered a simple and fast algorithm, it's easy to implement and can handle high-dimensional data. However, its performance can be affected by the independence assumption and it can be sensitive to irrelevant features and to the probability estimates.

## h. Ensemble methods
### Bagging
- Bagging (short for bootstrap aggregating) is an ensemble method that is used to improve the performance of a single learning algorithm by averaging the predictions of multiple models that are trained on different subsets of the data. The purpose of bagging is to reduce the variance of the predictions made by a single model and improve the overall performance of the ensemble.
- The basic idea behind bagging is to train multiple models on different samples of the training data. These samples are obtained by randomly selecting samples from the original training data with replacement. The process of selecting samples with replacement is called bootstrapping. Once the models are trained, the predictions made by each model are combined to make a final prediction. The most common way of combining the predictions is to take the average of the predictions for regression problems and the majority vote for classification problems.
- Bagging can be applied to a wide range of learning algorithms, including decision trees, neural networks, and support vector machines. One of the most popular algorithms that use bagging is Random Forest, which is an ensemble of decision trees trained on different subsets of the data.
- Bagging is considered as a powerful and simple ensemble method that can be used to improve the performance of a wide range of learning algorithms. It can effectively reduce the variance of the predictions, making the ensemble more robust to overfitting. However, it does not help to reduce bias, so it's not suited for high bias models. Additionally, it can be computationally expensive if the number of models in the ensemble is large or if the models are computationally expensive to train.

### Boosting 
- Boosting is an ensemble method that is used to improve the performance of a single learning algorithm by combining the predictions of multiple models that are trained sequentially. The purpose of boosting is to reduce the bias of the predictions made by a single model and improve the overall performance of the ensemble.
- The basic idea behind boosting is to train a sequence of weak models, where each model is trained to correct the mistakes made by the previous models in the sequence. The training process is done by adjusting the weights of the training examples, so that the examples that are misclassified by the previous models in the sequence are given more weight in the training of the next model. This way, the next model is forced to focus more on the examples that are difficult to classify. Once the models are trained, the predictions made by each model are combined to make a final prediction. The most common way of combining the predictions is to take a weighted average of the predictions, where the weights are based on the accuracy of the individual models.
- Boosting can be applied to a wide range of learning algorithms, including decision trees, neural networks, and support vector machines. Some of the most popular boosting algorithms include AdaBoost, Gradient Boosting, and XGBoost.
- Boosting is considered as a powerful ensemble method that can be used to improve the performance of a wide range of learning algorithms. It can effectively reduce the bias of the predictions, making the ensemble more robust to underfitting. However, it can also be sensitive to noisy data and outliers, and it can over-emphasize the importance of examples that are difficult to classify. Additionally, it can be computationally expensive if the number of models in the ensemble is large or if the models are computationally expensive to train.

### Stacking 
- Stacking is an ensemble method that is used to improve the performance of a group of learning algorithms by combining their predictions in a second-level or meta-model. The purpose of stacking is to leverage the strengths of multiple models to achieve improved performance, by combining their predictions in a way that takes into account their individual strengths and weaknesses.
- The basic idea behind stacking is to train a group of base models on the original training data, and then use their predictions as input features for a second-level or meta-model. This second-level model, also known as the meta-model, is trained to make a final prediction based on the predictions of the base models. The process can be repeated by adding more levels of models to make the ensemble more robust.
- Stacking can be applied to a wide range of learning algorithms, including decision trees, neural networks, and support vector machines. The base models can be trained using different techniques such as bagging, boosting, or different algorithms altogether.
- Stacking is considered a powerful ensemble method that can be used to improve the performance of a wide range of learning algorithms. It can effectively combine the strengths of multiple models to achieve improved performance. Additionally, it allows for more flexibility in the ensemble construction by allowing the use of different types of models at different levels. However, it can be computationally expensive if the number of models in the ensemble is large or if the models are computationally expensive to train. Also, it can require a large amount of data to achieve good performance, and the selection of the right models and their combination can be challenging.

### Random forests
- Random forests are a type of ensemble method that combines multiple decision trees to improve the performance of the model. They are an extension of the bagging technique applied to decision trees, where each tree is trained on a random subset of the data. The purpose of random forests is to reduce the variance of the predictions made by a single decision tree, and improve the overall performance of the ensemble.
- The basic idea behind random forests is to train multiple decision trees on different samples of the training data, and then average their predictions to make a final prediction. The samples are obtained by randomly selecting samples from the original training data with replacement, this process is called bootstrapping. Additionally, at each split of the decision tree, a random subset of the features is chosen as candidate for the best split, this is a technique called random subspace method.
- Random forests can be used for both classification and regression problems. They are considered a powerful and versatile algorithm, that can handle high-dimensional data, and can be used for a wide range of applications such as image recognition, text classification, and bioinformatics. They are relatively easy to implement, and they are robust to overfitting, because they average many decision trees, which reduces the variance of the predictions. However, they are not able to reduce bias, so they are not suited for high bias models, and they can be computationally expensive if the number of trees in the ensemble is large or if the decision trees are computationally expensive to train.

## i. Bayesian inference and believe networks
- Bayesian inference is a method of statistical inference that is based on Bayes' theorem, which states that the probability of an event occurring given some prior knowledge or data can be calculated by multiplying the probability of the event occurring independent of any prior knowledge by the probability of the prior knowledge given the event. In the context of supervised learning, Bayesian inference is used to make predictions about the target variable based on the input features by using probability distributions to represent the uncertainty of the model's parameters.
- Bayesian belief networks (BBN), also called Bayesian networks, are a type of probabilistic graphical model that are used to represent the relationships between variables in a probabilistic way. They are composed of a directed acyclic graph (DAG) where each node represents a random variable and the edges represent the probabilistic dependencies between the variables.
- The purpose of BBN is to provide a way to represent and reason about uncertain knowledge, by using probability distributions to represent the uncertainty of the variables and the relationships between them. They are used to model complex systems with multiple variables, and can handle missing data and hidden variables. They are particularly useful in applications such as medical diagnosis, image recognition, and natural language processing.
- In summary, Bayesian inference and Bayesian belief networks are probabilistic approaches that can be used to make predictions in supervised learning problems. They provide a way to handle uncertain knowledge and make predictions based on probability distributions. They are particularly useful for handling missing data and hidden variables and can be used in a wide range of applications. However, they can be computationally intensive, and require a good understanding of probability theory to implement and interpret the results.