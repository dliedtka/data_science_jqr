# 3.7.3 Statistics - Intervals Techniques

## a. Quartiles
- Quartiles are a type of interval measure in statistics used to divide a set of observations into four equal parts. They are used to describe the distribution of a set of data and to identify where values in the data set lie in relation to one another.
- In statistics, the quartiles are defined as the following:
    - The first quartile (Q1), also known as the lower quartile, is the value that separates the lowest 25% of the data from the rest.
    - The second quartile (Q2), also known as the median, is the value that separates the lowest 50% of the data from the highest 50%.
    - The third quartile (Q3), also known as the upper quartile, is the value that separates the lowest 75% of the data from the highest 25%.
- Quartiles are useful in identifying outliers, skewness, and the spread of data, and can be used to make comparisons between different data sets. They are also often used in conjunction with box plots to visualize the distribution of a set of data.

## b. Empirical Rule
- The empirical rule is a statistical tool that can be used to summarize the distribution of a dataset and make predictions about the likelihood of certain values occurring. The empirical rule states that for a normal distribution (i.e., a bell-shaped curve), approximately 68% of the data falls within one standard deviation of the mean, approximately 95% of the data falls within two standard deviations of the mean, and approximately 99.7% of the data falls within three standard deviations of the mean.
- The empirical rule can be used in a variety of applications, including quality control, hypothesis testing, and decision making. For example, in quality control, the empirical rule can be used to determine the likelihood of a product falling outside of a certain specification range. In hypothesis testing, the empirical rule can be used to test the hypothesis that a sample is drawn from a normal population. In decision making, the empirical rule can be used to calculate the probability of a certain event occurring and make informed decisions based on that information.
- In general, the empirical rule provides a quick and easy way to summarize the distribution of a dataset and make predictions about the likelihood of certain values occurring. It is a useful tool for both data analysis and decision making in a variety of fields, including engineering, business, and the social sciences.

## c. Z-Scores
- The purpose of Z-scores is to provide a standard way to compare a specific value to the mean of a set of values. A Z-score, also known as a standard score, represents the number of standard deviations a value is away from the mean of a set of values. In other words, Z-scores give us a way to measure how far a specific value deviates from the mean of a set of values.
- In the context of statistics, Z-scores are used to perform a number of tasks, including:  
    - Outlier detection: Z-scores can be used to identify outliers, or values that lie far away from the mean. Values with a Z-score greater than or equal to a certain threshold (e.g., 3 or -3) are typically considered outliers.
    - Data normalization: Z-scores can be used to normalize data, or transform it so that it has a mean of zero and a standard deviation of one. This can be useful for comparing data from different distributions or for making data more suitable for certain statistical methods.
    - Confidence intervals: Z-scores can be used to compute confidence intervals for a specific value, which represent a range of values that are likely to contain the true value with a certain level of confidence.
    - Hypothesis testing: Z-scores can be used to test hypotheses about the mean of a set of values. For example, a Z-score can be used to determine whether the mean of a set of values is significantly different from a known value.
- Overall, Z-scores are a useful tool for summarizing and comparing data in a standardized manner, and they are widely used in a variety of statistical applications.

## d. Confidence Intervals
- Confidence intervals are a key tool used in statistics to make estimates about a population based on a sample. The purpose of confidence intervals is to provide a range of values that are likely to contain the true value of a population parameter, such as the mean or proportion, with a certain degree of confidence. Confidence intervals are often used to make inferences about a population based on a sample of data.
- For example, if you were to collect a sample of data from a population and calculate the mean, you might find that the mean of your sample is different from the true mean of the population. Confidence intervals provide a way to quantify the uncertainty in your estimate of the population mean based on the sample mean and the variability in the sample. The confidence level is typically set by the researcher and represents the degree of certainty desired in the estimate. For example, a confidence level of 95% means that if the same sample were collected many times, 95% of the confidence intervals would contain the true population mean.
- Confidence intervals can be used to make decisions about population parameters and to test hypotheses about the population. For example, if a confidence interval for the population mean does not include a certain value, it can be concluded with a certain degree of confidence that the population mean is not equal to that value. Additionally, if two confidence intervals do not overlap, it can be concluded with a certain degree of confidence that the population parameters being estimated are different.
